#!/usr/bin/env python3

"""
ë¡œì»¬ë¼ì´ì œì´ì…˜ ì„±ëŠ¥ ë°ì´í„° ë¶„ì„ ë° ì‹œê°í™” ë„êµ¬

ì‚¬ìš©ë²•:
python3 localization_analysis.py --session SESSION_ID
python3 localization_analysis.py --compare SESSION1 SESSION2
python3 localization_analysis.py --list  # ì„¸ì…˜ ëª©ë¡ ë³´ê¸°
"""

import argparse
import pandas as pd
import matplotlib.pyplot as plt
import json
import os
from datetime import datetime
import numpy as np

class LocalizationAnalyzer:
    def __init__(self, data_dir="/home/f1/f1tenth_ws/localization_logs"):
        self.data_dir = data_dir

    def list_sessions(self):
        """ì‚¬ìš© ê°€ëŠ¥í•œ ì„¸ì…˜ ëª©ë¡ ì¶œë ¥"""
        if not os.path.exists(self.data_dir):
            print(f"ë°ì´í„° ë””ë ‰í„°ë¦¬ê°€ ì—†ìŠµë‹ˆë‹¤: {self.data_dir}")
            return

        sessions = []
        for file in os.listdir(self.data_dir):
            if file.startswith("session_summary_") and file.endswith(".json"):
                session_id = file.replace("session_summary_", "").replace(".json", "")
                sessions.append(session_id)

        print(f"\nğŸ“Š ì‚¬ìš© ê°€ëŠ¥í•œ ì„¸ì…˜ë“¤ ({len(sessions)}ê°œ):")
        print("=" * 50)

        for session_id in sorted(sessions):
            summary_file = os.path.join(self.data_dir, f"session_summary_{session_id}.json")
            try:
                with open(summary_file, 'r') as f:
                    summary = json.load(f)

                start_time = summary['session_info']['start_time']
                duration = summary['session_info']['duration_seconds']
                data_points = summary['session_info']['total_data_points']

                print(f"ğŸ”¹ {session_id}")
                print(f"   ì‹œì‘ ì‹œê°„: {start_time}")
                print(f"   ì§€ì† ì‹œê°„: {duration:.1f}ì´ˆ")
                print(f"   ë°ì´í„° í¬ì¸íŠ¸: {data_points}ê°œ")
                print()

            except Exception as e:
                print(f"âŒ {session_id}: ìš”ì•½ íŒŒì¼ ì½ê¸° ì‹¤íŒ¨ - {e}")

    def load_session_data(self, session_id):
        """ì„¸ì…˜ ë°ì´í„° ë¡œë“œ"""
        csv_file = os.path.join(self.data_dir, f"performance_{session_id}.csv")
        summary_file = os.path.join(self.data_dir, f"session_summary_{session_id}.json")

        if not os.path.exists(csv_file):
            raise FileNotFoundError(f"ì„¸ì…˜ ë°ì´í„° íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {csv_file}")

        # CSV ë°ì´í„° ë¡œë“œ
        df = pd.read_csv(csv_file)
        df['datetime'] = pd.to_datetime(df['datetime'])

        # ìš”ì•½ ë°ì´í„° ë¡œë“œ
        summary = None
        if os.path.exists(summary_file):
            with open(summary_file, 'r') as f:
                summary = json.load(f)

        return df, summary

    def visualize_session(self, session_id, save_plots=True):
        """ë‹¨ì¼ ì„¸ì…˜ ì‹œê°í™”"""
        print(f"\nğŸ“ˆ ì„¸ì…˜ {session_id} ë¶„ì„ ì¤‘...")

        try:
            df, summary = self.load_session_data(session_id)
        except FileNotFoundError as e:
            print(f"âŒ {e}")
            return

        # 4ê°œ ì„œë¸Œí”Œë¡¯ ìƒì„±
        fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 10))
        fig.suptitle(f'ë¡œì»¬ë¼ì´ì œì´ì…˜ ì„±ëŠ¥ ë¶„ì„ - {session_id}', fontsize=16)

        # 1. ì—…ë°ì´íŠ¸ ì£¼íŒŒìˆ˜
        valid_freq = df['update_frequency'].dropna()
        if not valid_freq.empty:
            ax1.plot(df.loc[valid_freq.index, 'datetime'], valid_freq, 'b-', alpha=0.7)
            ax1.axhline(y=20, color='r', linestyle='--', alpha=0.5, label='ê¶Œì¥ ìµœì†Œê°’ (20Hz)')
            ax1.set_title('ì—…ë°ì´íŠ¸ ì£¼íŒŒìˆ˜')
            ax1.set_ylabel('Hz')
            ax1.legend()
            ax1.grid(True, alpha=0.3)

        # 2. Map Alignment Score
        valid_align = df['alignment_score_mean'].dropna()
        if not valid_align.empty:
            ax2.plot(df.loc[valid_align.index, 'datetime'], valid_align, 'g-', alpha=0.7)
            ax2.axhline(y=0.85, color='g', linestyle='--', alpha=0.5, label='ì–‘í˜¸ (85%)')
            ax2.axhline(y=0.70, color='orange', linestyle='--', alpha=0.5, label='ë³´í†µ (70%)')
            ax2.set_title('Map Alignment Score')
            ax2.set_ylabel('ë§¤ì¹­ë¥ ')
            ax2.legend()
            ax2.grid(True, alpha=0.3)

        # 3. ìœ„ì¹˜ ë¶ˆí™•ì‹¤ì„±
        valid_unc = df['uncertainty_total'].dropna()
        if not valid_unc.empty:
            ax3.plot(df.loc[valid_unc.index, 'datetime'], valid_unc, 'r-', alpha=0.7)
            ax3.axhline(y=0.1, color='r', linestyle='--', alpha=0.5, label='ê¶Œì¥ ìµœëŒ€ê°’ (10cm)')
            ax3.set_title('ìœ„ì¹˜ ë¶ˆí™•ì‹¤ì„±')
            ax3.set_ylabel('ë¯¸í„° (m)')
            ax3.legend()
            ax3.grid(True, alpha=0.3)

        # 4. ì¥ì• ë¬¼ ê±°ë¦¬
        valid_dist = df['obstacle_distance_mean'].dropna()
        if not valid_dist.empty:
            ax4.plot(df.loc[valid_dist.index, 'datetime'], valid_dist, 'purple', alpha=0.7)
            ax4.axhline(y=0.15, color='g', linestyle='--', alpha=0.5, label='ì–‘í˜¸ (<15cm)')
            ax4.axhline(y=0.25, color='orange', linestyle='--', alpha=0.5, label='ë³´í†µ (<25cm)')
            ax4.set_title('í‰ê·  ì¥ì• ë¬¼ ê±°ë¦¬')
            ax4.set_ylabel('ë¯¸í„° (m)')
            ax4.legend()
            ax4.grid(True, alpha=0.3)

        plt.tight_layout()

        if save_plots:
            plot_file = os.path.join(self.data_dir, f"analysis_{session_id}.png")
            plt.savefig(plot_file, dpi=300, bbox_inches='tight')
            print(f"ğŸ“Š ì‹œê°í™” ì €ì¥ ì™„ë£Œ: {plot_file}")

        plt.show()

        # í†µê³„ ìš”ì•½ ì¶œë ¥
        if summary and 'performance_summary' in summary:
            self.print_session_summary(session_id, summary)

    def compare_sessions(self, session_ids, save_plots=True):
        """ì—¬ëŸ¬ ì„¸ì…˜ ë¹„êµ"""
        print(f"\nğŸ”„ ì„¸ì…˜ ë¹„êµ: {', '.join(session_ids)}")

        sessions_data = {}
        for session_id in session_ids:
            try:
                df, summary = self.load_session_data(session_id)
                sessions_data[session_id] = {'data': df, 'summary': summary}
            except FileNotFoundError:
                print(f"âŒ ì„¸ì…˜ {session_id} ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                continue

        if len(sessions_data) < 2:
            print("ë¹„êµí•  ìˆ˜ ìˆëŠ” ì„¸ì…˜ì´ ë¶€ì¡±í•©ë‹ˆë‹¤.")
            return

        # ë¹„êµ ì‹œê°í™”
        fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 10))
        fig.suptitle(f'ì„¸ì…˜ ë¹„êµ ë¶„ì„', fontsize=16)

        colors = ['blue', 'red', 'green', 'orange', 'purple']

        for i, (session_id, data) in enumerate(sessions_data.items()):
            df = data['data']
            color = colors[i % len(colors)]

            # ìƒëŒ€ ì‹œê°„ìœ¼ë¡œ ë³€í™˜ (ì„¸ì…˜ ì‹œì‘ë¶€í„°ì˜ ê²½ê³¼ ì‹œê°„)
            df['relative_time'] = (df['datetime'] - df['datetime'].iloc[0]).dt.total_seconds() / 60  # ë¶„ ë‹¨ìœ„

            # ê° ì§€í‘œ í”Œë¡¯
            metrics = [
                ('update_frequency', ax1, 'ì—…ë°ì´íŠ¸ ì£¼íŒŒìˆ˜ (Hz)'),
                ('alignment_score_mean', ax2, 'Map Alignment Score'),
                ('uncertainty_total', ax3, 'ìœ„ì¹˜ ë¶ˆí™•ì‹¤ì„± (m)'),
                ('obstacle_distance_mean', ax4, 'í‰ê·  ì¥ì• ë¬¼ ê±°ë¦¬ (m)')
            ]

            for metric, ax, ylabel in metrics:
                valid_data = df[metric].dropna()
                if not valid_data.empty:
                    ax.plot(df.loc[valid_data.index, 'relative_time'], valid_data,
                           color=color, alpha=0.7, label=session_id)
                    ax.set_ylabel(ylabel)
                    ax.set_xlabel('ì‹œê°„ (ë¶„)')
                    ax.legend()
                    ax.grid(True, alpha=0.3)

        plt.tight_layout()

        if save_plots:
            plot_file = os.path.join(self.data_dir, f"comparison_{'_vs_'.join(session_ids)}.png")
            plt.savefig(plot_file, dpi=300, bbox_inches='tight')
            print(f"ğŸ“Š ë¹„êµ ì‹œê°í™” ì €ì¥: {plot_file}")

        plt.show()

    def print_session_summary(self, session_id, summary):
        """ì„¸ì…˜ ìš”ì•½ í†µê³„ ì¶œë ¥"""
        print(f"\nğŸ“‹ ì„¸ì…˜ {session_id} ìš”ì•½ í†µê³„:")
        print("=" * 50)

        session_info = summary['session_info']
        print(f"â±ï¸  ì§€ì† ì‹œê°„: {session_info['duration_seconds']:.1f}ì´ˆ")
        print(f"ğŸ“Š ë°ì´í„° í¬ì¸íŠ¸: {session_info['total_data_points']}ê°œ")

        if 'performance_summary' in summary:
            perf = summary['performance_summary']

            metrics = [
                ('update_frequency', 'ì—…ë°ì´íŠ¸ ì£¼íŒŒìˆ˜', 'Hz'),
                ('alignment_score_mean', 'Map Alignment', ''),
                ('uncertainty_total', 'ìœ„ì¹˜ ë¶ˆí™•ì‹¤ì„±', 'm'),
                ('obstacle_distance_mean', 'ì¥ì• ë¬¼ ê±°ë¦¬', 'm')
            ]

            for key, name, unit in metrics:
                if key in perf:
                    stats = perf[key]
                    print(f"\n{name}:")
                    print(f"  í‰ê· : {stats['mean']:.3f} {unit}")
                    print(f"  í‘œì¤€í¸ì°¨: {stats['std']:.3f} {unit}")
                    print(f"  ë²”ìœ„: {stats['min']:.3f} ~ {stats['max']:.3f} {unit}")

def main():
    parser = argparse.ArgumentParser(description='ë¡œì»¬ë¼ì´ì œì´ì…˜ ì„±ëŠ¥ ë°ì´í„° ë¶„ì„')
    parser.add_argument('--session', help='ë¶„ì„í•  ì„¸ì…˜ ID')
    parser.add_argument('--compare', nargs='+', help='ë¹„êµí•  ì„¸ì…˜ IDë“¤')
    parser.add_argument('--list', action='store_true', help='ì‚¬ìš© ê°€ëŠ¥í•œ ì„¸ì…˜ ëª©ë¡ ë³´ê¸°')
    parser.add_argument('--data-dir', default='/home/f1/f1tenth_ws/localization_logs',
                       help='ë°ì´í„° ë””ë ‰í„°ë¦¬ ê²½ë¡œ')

    args = parser.parse_args()

    analyzer = LocalizationAnalyzer(args.data_dir)

    if args.list:
        analyzer.list_sessions()
    elif args.session:
        analyzer.visualize_session(args.session)
    elif args.compare:
        analyzer.compare_sessions(args.compare)
    else:
        print("ì˜µì…˜ì„ ì„ íƒí•´ì£¼ì„¸ìš”. --helpë¥¼ ì°¸ì¡°í•˜ì„¸ìš”.")

if __name__ == '__main__':
    main()

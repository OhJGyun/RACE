#!/usr/bin/env python3

"""
ë¡œì»¬ë¼ì´ì œì´ì…˜ ì„±ëŠ¥ í‰ê°€ í…ŒìŠ¤íŠ¸ ì½”ë“œ

ì—…ë°ì´íŠ¸ ì†ë„, ìœ„ì¹˜ ë¶„ì‚°, ì¶”ì • ì •í™•ë„ ë“±ì„ ì‹¤ì‹œê°„ìœ¼ë¡œ ëª¨ë‹ˆí„°ë§í•˜ê³  ë¶„ì„

ì‚¬ìš©ë²•:
ros2 run slam_nav localization_performance_test.py
"""

import rclpy
from rclpy.node import Node
from geometry_msgs.msg import PoseWithCovarianceStamped
from nav_msgs.msg import OccupancyGrid
from sensor_msgs.msg import LaserScan
from tf2_ros import Buffer, TransformListener
import numpy as np
import time
import math
import json
import csv
import os
from datetime import datetime
from collections import deque
import matplotlib.pyplot as plt
import matplotlib.dates as mdates

class LocalizationPerformanceTest(Node):
    def __init__(self):
        super().__init__('localization_performance_test')

        # êµ¬ë…ì ì„¤ì •
        self.amcl_pose_sub = self.create_subscription(
            PoseWithCovarianceStamped,
            '/amcl_pose',
            self.amcl_pose_callback,
            10
        )

        self.scan_sub = self.create_subscription(
            LaserScan,
            '/scan',
            self.scan_callback,
            10
        )

        self.map_sub = self.create_subscription(
            OccupancyGrid,
            '/map',
            self.map_callback,
            10
        )

        # TF ë¦¬ìŠ¤ë„ˆ
        self.tf_buffer = Buffer()
        self.tf_listener = TransformListener(self.tf_buffer, self)

        # ì„±ëŠ¥ ë°ì´í„° ì €ì¥
        self.pose_timestamps = deque(maxlen=1000)
        self.poses = deque(maxlen=1000)
        self.covariances = deque(maxlen=1000)

        # í†µê³„ ë³€ìˆ˜
        self.last_pose_time = None
        self.update_intervals = deque(maxlen=100)

        # ì´ë™ ê±°ë¦¬ ì¶”ì 
        self.last_position = None
        self.total_distance = 0.0
        self.position_history = deque(maxlen=500)

        # Map alignment ê´€ë ¨ ë³€ìˆ˜
        self.current_map = None
        self.current_scan = None
        self.current_pose = None
        self.alignment_scores = deque(maxlen=100)
        self.obstacle_distances = deque(maxlen=100)
        self.scan_timestamps = deque(maxlen=100)

        # ë°ì´í„° ì €ì¥ ê´€ë ¨ ë³€ìˆ˜
        self.session_start_time = datetime.now()
        self.session_id = self.session_start_time.strftime("%Y%m%d_%H%M%S")
        self.data_dir = "/home/f1/f1tenth_ws/localization_logs"
        self.ensure_data_directory()

        # ëˆ„ì  ë°ì´í„° ì €ì¥ìš© (ì œí•œ ì—†ìŒ)
        self.all_performance_data = []
        self.last_save_time = time.time()
        self.save_interval = 10.0  # 10ì´ˆë§ˆë‹¤ ì €ì¥

        # CSV íŒŒì¼ ê²½ë¡œ ì„¤ì •
        self.csv_filename = os.path.join(self.data_dir, f"localization_states_{self.session_id}.csv")
        self.state_data = []  # ìœ„ì¹˜ ìƒíƒœ ë²¡í„° ë°ì´í„° ì €ì¥ìš©

        # íƒ€ì´ë¨¸ ì„¤ì •
        self.create_timer(5.0, self.print_statistics)
        self.create_timer(self.save_interval, self.save_data_periodic)

        self.get_logger().info("ë¡œì»¬ë¼ì´ì œì´ì…˜ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì‹œì‘...")
        self.get_logger().info("AMCL pose ë°ì´í„°ë¥¼ ìˆ˜ì§‘ ì¤‘...")

    def amcl_pose_callback(self, msg):
        current_time = time.time()

        # ì—…ë°ì´íŠ¸ ì£¼ê¸° ê³„ì‚°
        if self.last_pose_time is not None:
            interval = current_time - self.last_pose_time
            self.update_intervals.append(interval)

        self.last_pose_time = current_time

        # í¬ì¦ˆ ë°ì´í„° ì €ì¥
        pose = msg.pose.pose
        self.pose_timestamps.append(current_time)
        self.poses.append(pose)

        # ê³µë¶„ì‚° ë°ì´í„° ì €ì¥
        cov = np.array(msg.pose.covariance).reshape(6, 6)
        self.covariances.append(cov)

        # ìœ„ì¹˜ ë³€í™” ì¶”ì 
        current_pos = [pose.position.x, pose.position.y]
        self.position_history.append(current_pos)

        if self.last_position is not None:
            distance = math.sqrt(
                (current_pos[0] - self.last_position[0])**2 +
                (current_pos[1] - self.last_position[1])**2
            )
            self.total_distance += distance

        self.last_position = current_pos
        self.current_pose = pose

        # ìƒíƒœ ë²¡í„° ë°ì´í„° ì €ì¥
        self.save_state_vector(current_time, pose, cov)

    def scan_callback(self, msg):
        """LiDAR ìŠ¤ìº” ë°ì´í„° ì½œë°±"""
        self.current_scan = msg
        self.scan_timestamps.append(time.time())

        # Map alignment ê³„ì‚° (ë§µê³¼ í¬ì¦ˆê°€ ëª¨ë‘ ìˆì„ ë•Œë§Œ)
        if self.current_map is not None and self.current_pose is not None:
            alignment_score = self.calculate_scan_map_alignment()
            if alignment_score is not None:
                self.alignment_scores.append(alignment_score)

            obstacle_distance = self.calculate_point_obstacle_distance()
            if obstacle_distance is not None:
                self.obstacle_distances.append(obstacle_distance)

    def map_callback(self, msg):
        """ë§µ ë°ì´í„° ì½œë°±"""
        self.current_map = msg
        self.get_logger().info("ë§µ ë°ì´í„° ìˆ˜ì‹  ì™„ë£Œ")

    def calculate_position_variance(self, window_size=50):
        """ìµœê·¼ Nê°œ ìœ„ì¹˜ì˜ ë¶„ì‚° ê³„ì‚°"""
        if len(self.position_history) < window_size:
            return None, None

        recent_positions = list(self.position_history)[-window_size:]
        positions = np.array(recent_positions)

        var_x = np.var(positions[:, 0])
        var_y = np.var(positions[:, 1])

        return var_x, var_y

    def calculate_update_rate(self):
        """ì—…ë°ì´íŠ¸ ì£¼ê¸° í†µê³„ ê³„ì‚°"""
        if len(self.update_intervals) == 0:
            return None, None, None

        intervals = np.array(self.update_intervals)
        mean_interval = np.mean(intervals)
        std_interval = np.std(intervals)
        frequency = 1.0 / mean_interval if mean_interval > 0 else 0

        return frequency, mean_interval, std_interval

    def calculate_covariance_stats(self):
        """ê³µë¶„ì‚° ë§¤íŠ¸ë¦­ìŠ¤ í†µê³„"""
        if len(self.covariances) == 0:
            return None, None, None, None

        recent_cov = self.covariances[-1]

        # ìœ„ì¹˜ ë¶ˆí™•ì‹¤ì„± (x, y)
        pos_uncertainty_x = math.sqrt(recent_cov[0, 0])
        pos_uncertainty_y = math.sqrt(recent_cov[1, 1])

        # ë°©í–¥ ë¶ˆí™•ì‹¤ì„±
        orientation_uncertainty = math.sqrt(recent_cov[5, 5])

        # ì „ì²´ ìœ„ì¹˜ ë¶ˆí™•ì‹¤ì„±
        total_pos_uncertainty = math.sqrt(pos_uncertainty_x**2 + pos_uncertainty_y**2)

        return pos_uncertainty_x, pos_uncertainty_y, orientation_uncertainty, total_pos_uncertainty

    def calculate_movement_stats(self):
        """ì´ë™ í†µê³„ ê³„ì‚°"""
        if len(self.position_history) < 2:
            return 0.0, 0.0

        # í˜„ì¬ ì†ë„ ì¶”ì • (ìµœê·¼ 5ê°œ í¬ì¸íŠ¸ ê¸°ë°˜)
        if len(self.position_history) >= 5 and len(self.pose_timestamps) >= 5:
            recent_positions = list(self.position_history)[-5:]
            recent_times = list(self.pose_timestamps)[-5:]

            time_diff = recent_times[-1] - recent_times[0]
            if time_diff > 0:
                distance_moved = math.sqrt(
                    (recent_positions[-1][0] - recent_positions[0][0])**2 +
                    (recent_positions[-1][1] - recent_positions[0][1])**2
                )
                current_velocity = distance_moved / time_diff
            else:
                current_velocity = 0.0
        else:
            current_velocity = 0.0

        return self.total_distance, current_velocity

    def calculate_scan_map_alignment(self):
        """ìŠ¤ìº”-ë§µ ì •ë ¬ ì ìˆ˜ ê³„ì‚°"""
        if self.current_scan is None or self.current_map is None or self.current_pose is None:
            return None

        try:
            # LiDAR í¬ì¸íŠ¸ë“¤ì„ ë§µ ì¢Œí‘œê³„ë¡œ ë³€í™˜
            scan_points = self.scan_to_cartesian(self.current_scan, self.current_pose)
            if len(scan_points) == 0:
                return None

            # ë§µì—ì„œ ì¥ì• ë¬¼ê³¼ì˜ ë§¤ì¹­ í™•ì¸
            matched_points = 0
            total_points = len(scan_points)

            for point in scan_points:
                if self.is_point_near_obstacle(point, self.current_map):
                    matched_points += 1

            alignment_score = matched_points / total_points if total_points > 0 else 0.0
            return alignment_score

        except Exception as e:
            self.get_logger().warn(f"Alignment ê³„ì‚° ì˜¤ë¥˜: {e}")
            return None

    def calculate_point_obstacle_distance(self):
        """ê° LiDAR í¬ì¸íŠ¸ì™€ ì¥ì• ë¬¼ ê°„ì˜ í‰ê·  ê±°ë¦¬"""
        if self.current_scan is None or self.current_map is None or self.current_pose is None:
            return None

        try:
            scan_points = self.scan_to_cartesian(self.current_scan, self.current_pose)
            if len(scan_points) == 0:
                return None

            distances = []
            for point in scan_points:
                min_dist = self.get_min_distance_to_obstacle(point, self.current_map)
                if min_dist is not None:
                    distances.append(min_dist)

            return np.mean(distances) if distances else None

        except Exception as e:
            self.get_logger().warn(f"Distance ê³„ì‚° ì˜¤ë¥˜: {e}")
            return None

    def scan_to_cartesian(self, scan, pose):
        """LiDAR ìŠ¤ìº”ì„ ë§µ ì¢Œí‘œê³„ì˜ ì¹´í…Œì‹œì•ˆ ì¢Œí‘œë¡œ ë³€í™˜"""
        points = []

        angle = scan.angle_min
        for range_val in scan.ranges:
            if scan.range_min <= range_val <= scan.range_max:
                # ë¡œë´‡ ì¢Œí‘œê³„ì—ì„œì˜ í¬ì¸íŠ¸
                local_x = range_val * math.cos(angle)
                local_y = range_val * math.sin(angle)

                # ë§µ ì¢Œí‘œê³„ë¡œ ë³€í™˜
                cos_theta = math.cos(pose.orientation.z)  # ê°„ë‹¨í•œ 2D ë³€í™˜
                sin_theta = math.sin(pose.orientation.z)

                global_x = pose.position.x + (local_x * cos_theta - local_y * sin_theta)
                global_y = pose.position.y + (local_x * sin_theta + local_y * cos_theta)

                points.append([global_x, global_y])

            angle += scan.angle_increment

        return np.array(points)

    def is_point_near_obstacle(self, point, map_msg, threshold=0.15):
        """í¬ì¸íŠ¸ê°€ ë§µì˜ ì¥ì• ë¬¼ ê·¼ì²˜ì— ìˆëŠ”ì§€ í™•ì¸"""
        # ë§µ ì¢Œí‘œë¥¼ ê·¸ë¦¬ë“œ ì¸ë±ìŠ¤ë¡œ ë³€í™˜
        grid_x = int((point[0] - map_msg.info.origin.position.x) / map_msg.info.resolution)
        grid_y = int((point[1] - map_msg.info.origin.position.y) / map_msg.info.resolution)

        # ë§µ ê²½ê³„ í™•ì¸
        if (grid_x < 0 or grid_x >= map_msg.info.width or
            grid_y < 0 or grid_y >= map_msg.info.height):
            return False

        # ì£¼ë³€ ì…€ë“¤ í™•ì¸ (threshold ë‚´ì˜ ì˜ì—­)
        search_radius = int(threshold / map_msg.info.resolution)

        for dx in range(-search_radius, search_radius + 1):
            for dy in range(-search_radius, search_radius + 1):
                check_x = grid_x + dx
                check_y = grid_y + dy

                if (0 <= check_x < map_msg.info.width and
                    0 <= check_y < map_msg.info.height):

                    index = check_y * map_msg.info.width + check_x
                    if index < len(map_msg.data) and map_msg.data[index] > 50:  # ì¥ì• ë¬¼ ì„ê³„ê°’
                        return True

        return False

    def get_min_distance_to_obstacle(self, point, map_msg, max_search_dist=1.0):
        """í¬ì¸íŠ¸ì—ì„œ ê°€ì¥ ê°€ê¹Œìš´ ì¥ì• ë¬¼ê¹Œì§€ì˜ ê±°ë¦¬"""
        min_distance = float('inf')

        # ë§µ ì¢Œí‘œë¥¼ ê·¸ë¦¬ë“œ ì¸ë±ìŠ¤ë¡œ ë³€í™˜
        grid_x = int((point[0] - map_msg.info.origin.position.x) / map_msg.info.resolution)
        grid_y = int((point[1] - map_msg.info.origin.position.y) / map_msg.info.resolution)

        # ê²€ìƒ‰ ë°˜ê²½ (ê·¸ë¦¬ë“œ ì…€ ë‹¨ìœ„)
        search_radius = int(max_search_dist / map_msg.info.resolution)

        for dx in range(-search_radius, search_radius + 1):
            for dy in range(-search_radius, search_radius + 1):
                check_x = grid_x + dx
                check_y = grid_y + dy

                if (0 <= check_x < map_msg.info.width and
                    0 <= check_y < map_msg.info.height):

                    index = check_y * map_msg.info.width + check_x
                    if index < len(map_msg.data) and map_msg.data[index] > 50:
                        # ì¥ì• ë¬¼ ë°œê²¬ - ê±°ë¦¬ ê³„ì‚°
                        obstacle_x = map_msg.info.origin.position.x + check_x * map_msg.info.resolution
                        obstacle_y = map_msg.info.origin.position.y + check_y * map_msg.info.resolution

                        distance = math.sqrt((point[0] - obstacle_x)**2 + (point[1] - obstacle_y)**2)
                        min_distance = min(min_distance, distance)

        return min_distance if min_distance != float('inf') else None

    def calculate_map_alignment_stats(self):
        """Map alignment í†µê³„ ê³„ì‚°"""
        if len(self.alignment_scores) == 0:
            return None, None, None, None

        # Alignment score í†µê³„
        recent_scores = list(self.alignment_scores)[-20:]  # ìµœê·¼ 20ê°œ
        mean_alignment = np.mean(recent_scores)
        std_alignment = np.std(recent_scores)

        # Obstacle distance í†µê³„
        obstacle_stats = None, None
        if len(self.obstacle_distances) > 0:
            recent_distances = list(self.obstacle_distances)[-20:]
            mean_distance = np.mean(recent_distances)
            std_distance = np.std(recent_distances)
            obstacle_stats = mean_distance, std_distance

        return mean_alignment, std_alignment, obstacle_stats[0], obstacle_stats[1]

    def ensure_data_directory(self):
        """ë°ì´í„° ì €ì¥ ë””ë ‰í„°ë¦¬ ìƒì„±"""
        if not os.path.exists(self.data_dir):
            os.makedirs(self.data_dir)
            self.get_logger().info(f"ë°ì´í„° ì €ì¥ ë””ë ‰í„°ë¦¬ ìƒì„±: {self.data_dir}")

    def save_state_vector(self, timestamp, pose, covariance):
        """ìƒíƒœ ë²¡í„° ë°ì´í„°ë¥¼ ì €ì¥"""
        # ì¿¼í„°ë‹ˆì–¸ì—ì„œ ì˜¤ì¼ëŸ¬ ê° ì¶”ì¶œ (ë‹¨ìˆœ 2D ê·¼ì‚¬)
        qx = pose.orientation.x
        qy = pose.orientation.y
        qz = pose.orientation.z
        qw = pose.orientation.w

        # 2D yaw ê°ë„ ê³„ì‚°
        yaw = math.atan2(2 * (qw * qz + qx * qy), 1 - 2 * (qy * qy + qz * qz))

        # ê³µë¶„ì‚° ì¶”ì¶œ
        cov_flat = covariance.flatten()

        state_record = {
            'timestamp': timestamp,
            'datetime': datetime.fromtimestamp(timestamp).isoformat(),
            'session_id': self.session_id,

            # ìœ„ì¹˜ ìƒíƒœ
            'x': pose.position.x,
            'y': pose.position.y,
            'z': pose.position.z,
            'yaw': yaw,

            # ê³µë¶„ì‚° ë§¤íŠ¸ë¦­ìŠ¤ (6x6 = 36ê°œ ìš”ì†Œ)
            'cov_xx': cov_flat[0],   # x-x
            'cov_xy': cov_flat[1],   # x-y
            'cov_xz': cov_flat[2],   # x-z
            'cov_x_roll': cov_flat[3],
            'cov_x_pitch': cov_flat[4],
            'cov_x_yaw': cov_flat[5],

            'cov_yy': cov_flat[7],   # y-y
            'cov_yz': cov_flat[8],   # y-z
            'cov_y_roll': cov_flat[9],
            'cov_y_pitch': cov_flat[10],
            'cov_y_yaw': cov_flat[11],

            'cov_zz': cov_flat[14],  # z-z
            'cov_z_roll': cov_flat[15],
            'cov_z_pitch': cov_flat[16],
            'cov_z_yaw': cov_flat[17],

            'cov_roll_roll': cov_flat[21],
            'cov_roll_pitch': cov_flat[22],
            'cov_roll_yaw': cov_flat[23],

            'cov_pitch_pitch': cov_flat[28],
            'cov_pitch_yaw': cov_flat[29],

            'cov_yaw_yaw': cov_flat[35],  # yaw-yaw

            # ë¶ˆí™•ì‹¤ì„± ì§€í‘œ
            'uncertainty_x': math.sqrt(abs(cov_flat[0])),
            'uncertainty_y': math.sqrt(abs(cov_flat[7])),
            'uncertainty_yaw': math.sqrt(abs(cov_flat[35])),
            'uncertainty_total': math.sqrt(cov_flat[0] + cov_flat[7])
        }

        self.state_data.append(state_record)

        # ì‹¤ì‹œê°„ìœ¼ë¡œ CSVì— ì €ì¥ (í—¤ë” ê´€ë¦¬)
        self.write_state_to_csv(state_record)

    def write_state_to_csv(self, state_record):
        """ìƒíƒœ ë°ì´í„°ë¥¼ CSV íŒŒì¼ì— ì‹¤ì‹œê°„ ì €ì¥"""
        file_exists = os.path.exists(self.csv_filename)

        with open(self.csv_filename, 'a', newline='') as f:
            writer = csv.DictWriter(f, fieldnames=state_record.keys())

            if not file_exists:
                writer.writeheader()
                self.get_logger().info(f"ìƒíƒœ ë²¡í„° CSV íŒŒì¼ ìƒì„±: {self.csv_filename}")

            writer.writerow(state_record)

    def collect_current_performance_data(self):
        """í˜„ì¬ ì„±ëŠ¥ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•˜ì—¬ ë”•ì…”ë„ˆë¦¬ë¡œ ë°˜í™˜"""
        current_time = time.time()

        # ê¸°ë³¸ ì„±ëŠ¥ ì§€í‘œ
        freq, mean_interval, std_interval = self.calculate_update_rate()
        var_x, var_y = self.calculate_position_variance()
        unc_x, unc_y, unc_theta, total_unc = self.calculate_covariance_stats()
        total_dist, velocity = self.calculate_movement_stats()
        mean_align, std_align, mean_dist, std_dist = self.calculate_map_alignment_stats()

        data_point = {
            'timestamp': current_time,
            'datetime': datetime.fromtimestamp(current_time).isoformat(),
            'session_id': self.session_id,

            # ì—…ë°ì´íŠ¸ ì„±ëŠ¥
            'update_frequency': freq,
            'update_interval_mean': mean_interval,
            'update_interval_std': std_interval,

            # ìœ„ì¹˜ ì•ˆì •ì„±
            'position_variance_x': var_x,
            'position_variance_y': var_y,
            'position_variance_total': (var_x + var_y) if var_x is not None and var_y is not None else None,

            # ë¶ˆí™•ì‹¤ì„±
            'uncertainty_x': unc_x,
            'uncertainty_y': unc_y,
            'uncertainty_theta': unc_theta,
            'uncertainty_total': total_unc,

            # ì´ë™ í†µê³„
            'total_distance': total_dist,
            'current_velocity': velocity,

            # Map alignment
            'alignment_score_mean': mean_align,
            'alignment_score_std': std_align,
            'obstacle_distance_mean': mean_dist,
            'obstacle_distance_std': std_dist,

            # í˜„ì¬ ìœ„ì¹˜ (ìˆëŠ” ê²½ìš°)
            'current_x': self.current_pose.position.x if self.current_pose else None,
            'current_y': self.current_pose.position.y if self.current_pose else None,
            'current_theta': self.current_pose.orientation.z if self.current_pose else None,

            # ë°ì´í„° ìˆ˜ì§‘ ìƒíƒœ
            'collected_poses': len(self.poses),
            'collected_scans': len(self.scan_timestamps),
            'alignment_analyses': len(self.alignment_scores)
        }

        return data_point

    def save_data_periodic(self):
        """ì£¼ê¸°ì ìœ¼ë¡œ ë°ì´í„° ì €ì¥"""
        if len(self.poses) < 5:  # ì¶©ë¶„í•œ ë°ì´í„°ê°€ ì—†ìœ¼ë©´ ì €ì¥í•˜ì§€ ì•ŠìŒ
            return

        current_data = self.collect_current_performance_data()
        if current_data:
            self.all_performance_data.append(current_data)

            # CSV íŒŒì¼ë¡œ ì €ì¥ (ì¶”ê°€ ëª¨ë“œ)
            csv_file = os.path.join(self.data_dir, f"performance_{self.session_id}.csv")
            self.save_to_csv(current_data, csv_file)

    def save_to_csv(self, data_point, csv_file):
        """ë‹¨ì¼ ë°ì´í„° í¬ì¸íŠ¸ë¥¼ CSVì— ì €ì¥"""
        file_exists = os.path.exists(csv_file)

        with open(csv_file, 'a', newline='') as f:
            writer = csv.DictWriter(f, fieldnames=data_point.keys())

            if not file_exists:
                writer.writeheader()

            writer.writerow(data_point)

    def save_session_summary(self):
        """ì„¸ì…˜ ì¢…ë£Œ ì‹œ ì „ì²´ ìš”ì•½ ì €ì¥"""
        if not self.all_performance_data:
            return

        summary_file = os.path.join(self.data_dir, f"session_summary_{self.session_id}.json")

        # ì„¸ì…˜ ìš”ì•½ í†µê³„ ê³„ì‚°
        summary = {
            'session_info': {
                'session_id': self.session_id,
                'start_time': self.session_start_time.isoformat(),
                'end_time': datetime.now().isoformat(),
                'duration_seconds': time.time() - self.pose_timestamps[0] if self.pose_timestamps else 0,
                'total_data_points': len(self.all_performance_data)
            },
            'performance_summary': self.calculate_session_statistics(),
            'raw_data_file': f"performance_{self.session_id}.csv"
        }

        with open(summary_file, 'w') as f:
            json.dump(summary, f, indent=2)

        self.get_logger().info(f"ì„¸ì…˜ ìš”ì•½ ì €ì¥ ì™„ë£Œ: {summary_file}")

    def calculate_session_statistics(self):
        """ì „ì²´ ì„¸ì…˜ì˜ í†µê³„ ê³„ì‚°"""
        if not self.all_performance_data:
            return {}

        # ìœ íš¨í•œ ë°ì´í„°ë§Œ í•„í„°ë§
        valid_data = [d for d in self.all_performance_data if d.get('update_frequency') is not None]

        if not valid_data:
            return {}

        stats = {}

        # ê° ì§€í‘œë³„ í†µê³„ ê³„ì‚°
        numeric_fields = [
            'update_frequency', 'position_variance_total', 'uncertainty_total',
            'current_velocity', 'alignment_score_mean', 'obstacle_distance_mean'
        ]

        for field in numeric_fields:
            values = [d[field] for d in valid_data if d.get(field) is not None]
            if values:
                stats[field] = {
                    'mean': np.mean(values),
                    'std': np.std(values),
                    'min': np.min(values),
                    'max': np.max(values),
                    'median': np.median(values)
                }

        return stats

    def print_statistics(self):
        """ì£¼ê¸°ì ìœ¼ë¡œ í†µê³„ ì¶œë ¥"""
        if len(self.poses) < 5:
            self.get_logger().info("ë°ì´í„° ìˆ˜ì§‘ ì¤‘... (ì¶©ë¶„í•œ ë°ì´í„° í•„ìš”)")
            return

        self.get_logger().info("\n" + "="*80)
        self.get_logger().info("ë¡œì»¬ë¼ì´ì œì´ì…˜ ì„±ëŠ¥ í†µê³„")
        self.get_logger().info("="*80)

        # 1. ì—…ë°ì´íŠ¸ ì„±ëŠ¥
        freq, mean_interval, std_interval = self.calculate_update_rate()
        if freq is not None:
            self.get_logger().info(f"ğŸ“Š ì—…ë°ì´íŠ¸ ì„±ëŠ¥:")
            self.get_logger().info(f"   - ì£¼íŒŒìˆ˜: {freq:.2f} Hz")
            self.get_logger().info(f"   - í‰ê·  ê°„ê²©: {mean_interval*1000:.1f} ms")
            self.get_logger().info(f"   - ê°„ê²© í¸ì°¨: Â±{std_interval*1000:.1f} ms")

            if freq < 20:
                self.get_logger().warn("âš ï¸  ì—…ë°ì´íŠ¸ ì£¼íŒŒìˆ˜ê°€ ë‚®ìŠµë‹ˆë‹¤ (20Hz ì´ìƒ ê¶Œì¥)")
            else:
                self.get_logger().info("âœ… ì—…ë°ì´íŠ¸ ì£¼íŒŒìˆ˜ ì–‘í˜¸")

        # 2. ìœ„ì¹˜ ë¶„ì‚° (ì•ˆì •ì„±)
        var_x, var_y = self.calculate_position_variance()
        if var_x is not None:
            self.get_logger().info(f"\nğŸ“ ìœ„ì¹˜ ì•ˆì •ì„± (ìµœê·¼ 50ê°œ ìƒ˜í”Œ):")
            self.get_logger().info(f"   - Xì¶• ë¶„ì‚°: {var_x:.6f} mÂ²")
            self.get_logger().info(f"   - Yì¶• ë¶„ì‚°: {var_y:.6f} mÂ²")
            self.get_logger().info(f"   - ì´ ë¶„ì‚°: {var_x + var_y:.6f} mÂ²")

            if var_x + var_y > 0.001:  # 1mmÂ²
                self.get_logger().warn("âš ï¸  ìœ„ì¹˜ ë¶„ì‚°ì´ ë†’ìŠµë‹ˆë‹¤ (ë¶ˆì•ˆì •)")
            else:
                self.get_logger().info("âœ… ìœ„ì¹˜ ì¶”ì • ì•ˆì •")

        # 3. ë¶ˆí™•ì‹¤ì„± (ê³µë¶„ì‚°)
        unc_x, unc_y, unc_theta, total_unc = self.calculate_covariance_stats()
        if unc_x is not None:
            self.get_logger().info(f"\nğŸ¯ ì¶”ì • ë¶ˆí™•ì‹¤ì„±:")
            self.get_logger().info(f"   - Xì¶• ë¶ˆí™•ì‹¤ì„±: Â±{unc_x:.3f} m")
            self.get_logger().info(f"   - Yì¶• ë¶ˆí™•ì‹¤ì„±: Â±{unc_y:.3f} m")
            self.get_logger().info(f"   - ë°©í–¥ ë¶ˆí™•ì‹¤ì„±: Â±{math.degrees(unc_theta):.1f}Â°")
            self.get_logger().info(f"   - ì´ ìœ„ì¹˜ ë¶ˆí™•ì‹¤ì„±: Â±{total_unc:.3f} m")

            if total_unc > 0.1:  # 10cm
                self.get_logger().warn("âš ï¸  ìœ„ì¹˜ ë¶ˆí™•ì‹¤ì„±ì´ ë†’ìŠµë‹ˆë‹¤")
            else:
                self.get_logger().info("âœ… ìœ„ì¹˜ ë¶ˆí™•ì‹¤ì„± ì–‘í˜¸")

        # 4. ì´ë™ í†µê³„
        total_dist, velocity = self.calculate_movement_stats()
        self.get_logger().info(f"\nğŸš— ì´ë™ í†µê³„:")
        self.get_logger().info(f"   - ì´ ì´ë™ê±°ë¦¬: {total_dist:.2f} m")
        self.get_logger().info(f"   - í˜„ì¬ ì†ë„: {velocity:.2f} m/s ({velocity*3.6:.1f} km/h)")

        # 5. Map Alignment ì„±ëŠ¥
        mean_align, std_align, mean_dist, std_dist = self.calculate_map_alignment_stats()
        if mean_align is not None:
            self.get_logger().info(f"\nğŸ—ºï¸  Map Alignment ì„±ëŠ¥:")
            self.get_logger().info(f"   - ìŠ¤ìº”-ë§µ ë§¤ì¹­ë¥ : {mean_align:.3f} ({mean_align*100:.1f}%)")
            self.get_logger().info(f"   - ë§¤ì¹­ë¥  í¸ì°¨: Â±{std_align:.3f}")

            if mean_align > 0.85:
                self.get_logger().info("âœ… ìŠ¤ìº”-ë§µ ì •ë ¬ ìƒíƒœ ì–‘í˜¸")
            elif mean_align > 0.70:
                self.get_logger().warn("âš ï¸  ìŠ¤ìº”-ë§µ ì •ë ¬ ìƒíƒœ ë³´í†µ")
            else:
                self.get_logger().warn("âŒ ìŠ¤ìº”-ë§µ ì •ë ¬ ìƒíƒœ ë¶ˆëŸ‰")

            if mean_dist is not None:
                self.get_logger().info(f"   - í‰ê·  ì¥ì• ë¬¼ ê±°ë¦¬: {mean_dist:.3f} m")
                self.get_logger().info(f"   - ê±°ë¦¬ í¸ì°¨: Â±{std_dist:.3f} m")

                if mean_dist < 0.15:
                    self.get_logger().info("âœ… ì¥ì• ë¬¼ ì •ë ¬ ì •í™•ë„ ì–‘í˜¸")
                elif mean_dist < 0.25:
                    self.get_logger().warn("âš ï¸  ì¥ì• ë¬¼ ì •ë ¬ ì •í™•ë„ ë³´í†µ")
                else:
                    self.get_logger().warn("âŒ ì¥ì• ë¬¼ ì •ë ¬ ì •í™•ë„ ë¶ˆëŸ‰")

        # 6. ë°ì´í„° ìˆ˜ì§‘ ì •ë³´
        self.get_logger().info(f"\nğŸ“ˆ ë°ì´í„° ìˆ˜ì§‘:")
        self.get_logger().info(f"   - ìˆ˜ì§‘ëœ í¬ì¦ˆ: {len(self.poses)}ê°œ")
        self.get_logger().info(f"   - ìˆ˜ì§‘ëœ ìŠ¤ìº”: {len(self.scan_timestamps)}ê°œ")
        self.get_logger().info(f"   - ì •ë ¬ ë¶„ì„ íšŸìˆ˜: {len(self.alignment_scores)}ê°œ")
        self.get_logger().info(f"   - ìˆ˜ì§‘ ì‹œê°„: {(self.pose_timestamps[-1] - self.pose_timestamps[0]):.1f}ì´ˆ")
        self.get_logger().info(f"   - ë°ì´í„° ì €ì¥ ìœ„ì¹˜: {self.data_dir}")
        self.get_logger().info(f"   - ìƒíƒœ ë²¡í„° ì €ì¥: {len(self.state_data)}ê°œ (CSV: {self.csv_filename})")

    def cleanup_and_save(self):
        """ì¢…ë£Œ ì‹œ ì •ë¦¬ ë° ìµœì¢… ì €ì¥"""
        self.save_session_summary()
        self.get_logger().info("ë°ì´í„° ì €ì¥ ì™„ë£Œ. ì‹œê°í™”ë¥¼ ìœ„í•´ analysis ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.")
        self.get_logger().info(f"ìƒíƒœ ë²¡í„° CSV íŒŒì¼: {self.csv_filename}")
        self.get_logger().info(f"ì´ {len(self.state_data)}ê°œì˜ ìƒíƒœ ë²¡í„°ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

def create_visualization_script():
    """ë°ì´í„° ë¶„ì„ ë° ì‹œê°í™”ë¥¼ ìœ„í•œ ë³„ë„ ìŠ¤í¬ë¦½íŠ¸ ìƒì„±"""
    analysis_script = '''#!/usr/bin/env python3

"""
ë¡œì»¬ë¼ì´ì œì´ì…˜ ì„±ëŠ¥ ë°ì´í„° ë¶„ì„ ë° ì‹œê°í™” ë„êµ¬

ì‚¬ìš©ë²•:
python3 localization_analysis.py --session SESSION_ID
python3 localization_analysis.py --compare SESSION1 SESSION2
python3 localization_analysis.py --list  # ì„¸ì…˜ ëª©ë¡ ë³´ê¸°
"""

import argparse
import pandas as pd
import matplotlib.pyplot as plt
import json
import os
from datetime import datetime
import numpy as np

class LocalizationAnalyzer:
    def __init__(self, data_dir="/home/f1/f1tenth_ws/localization_logs"):
        self.data_dir = data_dir

    def list_sessions(self):
        """ì‚¬ìš© ê°€ëŠ¥í•œ ì„¸ì…˜ ëª©ë¡ ì¶œë ¥"""
        if not os.path.exists(self.data_dir):
            print(f"ë°ì´í„° ë””ë ‰í„°ë¦¬ê°€ ì—†ìŠµë‹ˆë‹¤: {self.data_dir}")
            return

        sessions = []
        for file in os.listdir(self.data_dir):
            if file.startswith("session_summary_") and file.endswith(".json"):
                session_id = file.replace("session_summary_", "").replace(".json", "")
                sessions.append(session_id)

        print(f"\\nğŸ“Š ì‚¬ìš© ê°€ëŠ¥í•œ ì„¸ì…˜ë“¤ ({len(sessions)}ê°œ):")
        print("=" * 50)

        for session_id in sorted(sessions):
            summary_file = os.path.join(self.data_dir, f"session_summary_{session_id}.json")
            try:
                with open(summary_file, 'r') as f:
                    summary = json.load(f)

                start_time = summary['session_info']['start_time']
                duration = summary['session_info']['duration_seconds']
                data_points = summary['session_info']['total_data_points']

                print(f"ğŸ”¹ {session_id}")
                print(f"   ì‹œì‘ ì‹œê°„: {start_time}")
                print(f"   ì§€ì† ì‹œê°„: {duration:.1f}ì´ˆ")
                print(f"   ë°ì´í„° í¬ì¸íŠ¸: {data_points}ê°œ")
                print()

            except Exception as e:
                print(f"âŒ {session_id}: ìš”ì•½ íŒŒì¼ ì½ê¸° ì‹¤íŒ¨ - {e}")

    def load_session_data(self, session_id):
        """ì„¸ì…˜ ë°ì´í„° ë¡œë“œ"""
        csv_file = os.path.join(self.data_dir, f"performance_{session_id}.csv")
        summary_file = os.path.join(self.data_dir, f"session_summary_{session_id}.json")

        if not os.path.exists(csv_file):
            raise FileNotFoundError(f"ì„¸ì…˜ ë°ì´í„° íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {csv_file}")

        # CSV ë°ì´í„° ë¡œë“œ
        df = pd.read_csv(csv_file)
        df['datetime'] = pd.to_datetime(df['datetime'])

        # ìš”ì•½ ë°ì´í„° ë¡œë“œ
        summary = None
        if os.path.exists(summary_file):
            with open(summary_file, 'r') as f:
                summary = json.load(f)

        return df, summary

    def visualize_session(self, session_id, save_plots=True):
        """ë‹¨ì¼ ì„¸ì…˜ ì‹œê°í™”"""
        print(f"\\nğŸ“ˆ ì„¸ì…˜ {session_id} ë¶„ì„ ì¤‘...")

        try:
            df, summary = self.load_session_data(session_id)
        except FileNotFoundError as e:
            print(f"âŒ {e}")
            return

        # 4ê°œ ì„œë¸Œí”Œë¡¯ ìƒì„±
        fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 10))
        fig.suptitle(f'ë¡œì»¬ë¼ì´ì œì´ì…˜ ì„±ëŠ¥ ë¶„ì„ - {session_id}', fontsize=16)

        # 1. ì—…ë°ì´íŠ¸ ì£¼íŒŒìˆ˜
        valid_freq = df['update_frequency'].dropna()
        if not valid_freq.empty:
            ax1.plot(df.loc[valid_freq.index, 'datetime'], valid_freq, 'b-', alpha=0.7)
            ax1.axhline(y=20, color='r', linestyle='--', alpha=0.5, label='ê¶Œì¥ ìµœì†Œê°’ (20Hz)')
            ax1.set_title('ì—…ë°ì´íŠ¸ ì£¼íŒŒìˆ˜')
            ax1.set_ylabel('Hz')
            ax1.legend()
            ax1.grid(True, alpha=0.3)

        # 2. Map Alignment Score
        valid_align = df['alignment_score_mean'].dropna()
        if not valid_align.empty:
            ax2.plot(df.loc[valid_align.index, 'datetime'], valid_align, 'g-', alpha=0.7)
            ax2.axhline(y=0.85, color='g', linestyle='--', alpha=0.5, label='ì–‘í˜¸ (85%)')
            ax2.axhline(y=0.70, color='orange', linestyle='--', alpha=0.5, label='ë³´í†µ (70%)')
            ax2.set_title('Map Alignment Score')
            ax2.set_ylabel('ë§¤ì¹­ë¥ ')
            ax2.legend()
            ax2.grid(True, alpha=0.3)

        # 3. ìœ„ì¹˜ ë¶ˆí™•ì‹¤ì„±
        valid_unc = df['uncertainty_total'].dropna()
        if not valid_unc.empty:
            ax3.plot(df.loc[valid_unc.index, 'datetime'], valid_unc, 'r-', alpha=0.7)
            ax3.axhline(y=0.1, color='r', linestyle='--', alpha=0.5, label='ê¶Œì¥ ìµœëŒ€ê°’ (10cm)')
            ax3.set_title('ìœ„ì¹˜ ë¶ˆí™•ì‹¤ì„±')
            ax3.set_ylabel('ë¯¸í„° (m)')
            ax3.legend()
            ax3.grid(True, alpha=0.3)

        # 4. ì¥ì• ë¬¼ ê±°ë¦¬
        valid_dist = df['obstacle_distance_mean'].dropna()
        if not valid_dist.empty:
            ax4.plot(df.loc[valid_dist.index, 'datetime'], valid_dist, 'purple', alpha=0.7)
            ax4.axhline(y=0.15, color='g', linestyle='--', alpha=0.5, label='ì–‘í˜¸ (<15cm)')
            ax4.axhline(y=0.25, color='orange', linestyle='--', alpha=0.5, label='ë³´í†µ (<25cm)')
            ax4.set_title('í‰ê·  ì¥ì• ë¬¼ ê±°ë¦¬')
            ax4.set_ylabel('ë¯¸í„° (m)')
            ax4.legend()
            ax4.grid(True, alpha=0.3)

        plt.tight_layout()

        if save_plots:
            plot_file = os.path.join(self.data_dir, f"analysis_{session_id}.png")
            plt.savefig(plot_file, dpi=300, bbox_inches='tight')
            print(f"ğŸ“Š ì‹œê°í™” ì €ì¥ ì™„ë£Œ: {plot_file}")

        plt.show()

        # í†µê³„ ìš”ì•½ ì¶œë ¥
        if summary and 'performance_summary' in summary:
            self.print_session_summary(session_id, summary)

    def compare_sessions(self, session_ids, save_plots=True):
        """ì—¬ëŸ¬ ì„¸ì…˜ ë¹„êµ"""
        print(f"\\nğŸ”„ ì„¸ì…˜ ë¹„êµ: {', '.join(session_ids)}")

        sessions_data = {}
        for session_id in session_ids:
            try:
                df, summary = self.load_session_data(session_id)
                sessions_data[session_id] = {'data': df, 'summary': summary}
            except FileNotFoundError:
                print(f"âŒ ì„¸ì…˜ {session_id} ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                continue

        if len(sessions_data) < 2:
            print("ë¹„êµí•  ìˆ˜ ìˆëŠ” ì„¸ì…˜ì´ ë¶€ì¡±í•©ë‹ˆë‹¤.")
            return

        # ë¹„êµ ì‹œê°í™”
        fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 10))
        fig.suptitle(f'ì„¸ì…˜ ë¹„êµ ë¶„ì„', fontsize=16)

        colors = ['blue', 'red', 'green', 'orange', 'purple']

        for i, (session_id, data) in enumerate(sessions_data.items()):
            df = data['data']
            color = colors[i % len(colors)]

            # ìƒëŒ€ ì‹œê°„ìœ¼ë¡œ ë³€í™˜ (ì„¸ì…˜ ì‹œì‘ë¶€í„°ì˜ ê²½ê³¼ ì‹œê°„)
            df['relative_time'] = (df['datetime'] - df['datetime'].iloc[0]).dt.total_seconds() / 60  # ë¶„ ë‹¨ìœ„

            # ê° ì§€í‘œ í”Œë¡¯
            metrics = [
                ('update_frequency', ax1, 'ì—…ë°ì´íŠ¸ ì£¼íŒŒìˆ˜ (Hz)'),
                ('alignment_score_mean', ax2, 'Map Alignment Score'),
                ('uncertainty_total', ax3, 'ìœ„ì¹˜ ë¶ˆí™•ì‹¤ì„± (m)'),
                ('obstacle_distance_mean', ax4, 'í‰ê·  ì¥ì• ë¬¼ ê±°ë¦¬ (m)')
            ]

            for metric, ax, ylabel in metrics:
                valid_data = df[metric].dropna()
                if not valid_data.empty:
                    ax.plot(df.loc[valid_data.index, 'relative_time'], valid_data,
                           color=color, alpha=0.7, label=session_id)
                    ax.set_ylabel(ylabel)
                    ax.set_xlabel('ì‹œê°„ (ë¶„)')
                    ax.legend()
                    ax.grid(True, alpha=0.3)

        plt.tight_layout()

        if save_plots:
            plot_file = os.path.join(self.data_dir, f"comparison_{'_vs_'.join(session_ids)}.png")
            plt.savefig(plot_file, dpi=300, bbox_inches='tight')
            print(f"ğŸ“Š ë¹„êµ ì‹œê°í™” ì €ì¥: {plot_file}")

        plt.show()

    def print_session_summary(self, session_id, summary):
        """ì„¸ì…˜ ìš”ì•½ í†µê³„ ì¶œë ¥"""
        print(f"\\nğŸ“‹ ì„¸ì…˜ {session_id} ìš”ì•½ í†µê³„:")
        print("=" * 50)

        session_info = summary['session_info']
        print(f"â±ï¸  ì§€ì† ì‹œê°„: {session_info['duration_seconds']:.1f}ì´ˆ")
        print(f"ğŸ“Š ë°ì´í„° í¬ì¸íŠ¸: {session_info['total_data_points']}ê°œ")

        if 'performance_summary' in summary:
            perf = summary['performance_summary']

            metrics = [
                ('update_frequency', 'ì—…ë°ì´íŠ¸ ì£¼íŒŒìˆ˜', 'Hz'),
                ('alignment_score_mean', 'Map Alignment', ''),
                ('uncertainty_total', 'ìœ„ì¹˜ ë¶ˆí™•ì‹¤ì„±', 'm'),
                ('obstacle_distance_mean', 'ì¥ì• ë¬¼ ê±°ë¦¬', 'm')
            ]

            for key, name, unit in metrics:
                if key in perf:
                    stats = perf[key]
                    print(f"\\n{name}:")
                    print(f"  í‰ê· : {stats['mean']:.3f} {unit}")
                    print(f"  í‘œì¤€í¸ì°¨: {stats['std']:.3f} {unit}")
                    print(f"  ë²”ìœ„: {stats['min']:.3f} ~ {stats['max']:.3f} {unit}")

def main():
    parser = argparse.ArgumentParser(description='ë¡œì»¬ë¼ì´ì œì´ì…˜ ì„±ëŠ¥ ë°ì´í„° ë¶„ì„')
    parser.add_argument('--session', help='ë¶„ì„í•  ì„¸ì…˜ ID')
    parser.add_argument('--compare', nargs='+', help='ë¹„êµí•  ì„¸ì…˜ IDë“¤')
    parser.add_argument('--list', action='store_true', help='ì‚¬ìš© ê°€ëŠ¥í•œ ì„¸ì…˜ ëª©ë¡ ë³´ê¸°')
    parser.add_argument('--data-dir', default='/home/f1/f1tenth_ws/localization_logs',
                       help='ë°ì´í„° ë””ë ‰í„°ë¦¬ ê²½ë¡œ')

    args = parser.parse_args()

    analyzer = LocalizationAnalyzer(args.data_dir)

    if args.list:
        analyzer.list_sessions()
    elif args.session:
        analyzer.visualize_session(args.session)
    elif args.compare:
        analyzer.compare_sessions(args.compare)
    else:
        print("ì˜µì…˜ì„ ì„ íƒí•´ì£¼ì„¸ìš”. --helpë¥¼ ì°¸ì¡°í•˜ì„¸ìš”.")

if __name__ == '__main__':
    main()
'''

    analysis_file = "/home/f1/f1tenth_ws/src/slam_nav/scripts/localization_analysis.py"
    with open(analysis_file, 'w') as f:
        f.write(analysis_script)

    # ì‹¤í–‰ ê¶Œí•œ ë¶€ì—¬
    os.chmod(analysis_file, 0o755)
    print(f"âœ… ë¶„ì„ ìŠ¤í¬ë¦½íŠ¸ ìƒì„± ì™„ë£Œ: {analysis_file}")

def main():
    rclpy.init()

    print("\n" + "="*80)
    print("F1TENTH ë¡œì»¬ë¼ì´ì œì´ì…˜ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸")
    print("="*80)
    print("ì´ ë„êµ¬ëŠ” AMCL ë¡œì»¬ë¼ì´ì œì´ì…˜ì˜ ì„±ëŠ¥ì„ ì‹¤ì‹œê°„ìœ¼ë¡œ ë¶„ì„í•©ë‹ˆë‹¤.")
    print("\nì¸¡ì • í•­ëª©:")
    print("- ì—…ë°ì´íŠ¸ ì£¼íŒŒìˆ˜ ë° ì•ˆì •ì„±")
    print("- ìœ„ì¹˜ ì¶”ì • ë¶„ì‚° (ì•ˆì •ì„±)")
    print("- ë¶ˆí™•ì‹¤ì„± (ê³µë¶„ì‚° ë§¤íŠ¸ë¦­ìŠ¤)")
    print("- ì´ë™ í†µê³„")
    print("- Map Alignment (ìŠ¤ìº”-ë§µ ì •ë ¬)")
    print("- ì¥ì• ë¬¼ ê±°ë¦¬ ë¶„ì„")
    print("\në¡œë´‡ì„ ì´ë™ì‹œí‚¤ë©´ì„œ ê²°ê³¼ë¥¼ ê´€ì°°í•˜ì„¸ìš”.")
    print("Ctrl+Cë¡œ ì¢…ë£Œí•©ë‹ˆë‹¤.")
    print("="*80)

    # ë¶„ì„ ìŠ¤í¬ë¦½íŠ¸ ìƒì„± (ì²˜ìŒ ì‹¤í–‰ ì‹œì—ë§Œ)
    create_visualization_script()

    node = LocalizationPerformanceTest()

    try:
        rclpy.spin(node)
    except KeyboardInterrupt:
        print("\n\ní…ŒìŠ¤íŠ¸ê°€ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")
        node.cleanup_and_save()
    finally:
        node.destroy_node()
        if rclpy.ok():
            rclpy.shutdown()

if __name__ == '__main__':
    main()